平台起训练作业时出现卡顿分析
=============================================================


问题环境分析
-------------------------------------------------------------

* k8s 集群中心节点（Master）负载NFS，平台，平台DB，NGINX

* 各节点使用相同的（master节点业务层）IP访问NFS，也是平台WEB对外的访问IP

* 训练POD采用的时hostnetwork,分布式训练任务不通节点之间ssh，加载数据的链接都是走相同的业务层IP：

```bash
thomas@6eb6069f-3629-4c31-a29a-45690d38f848-ps0:~$ cat /etc/hosts 
# Kubernetes-managed hosts file.
127.0.0.1       localhost
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
fe00::0 ip6-mcastprefix
fe00::1 ip6-allnodes
fe00::2 ip6-allrouters
10.32.0.3       6eb6069f-3629-4c31-a29a-45690d38f848-ps0
10.32.0.3       ps-0
192.168.1.11    worker-0
192.168.1.8     worker-1
thomas@6eb6069f-3629-4c31-a29a-45690d38f848-ps0:~$ 
```

测试案例对比分析
------------------------------------------------------------

* openlab测试oceanstore的案例中

    1. 存储节点，MindX DL和MindX DL-add节点时独立与A800-9010集群的
    2. 不通节点使用不同的IP链路访问OceanStore 5510F V5
    3. 手工启动训练为在裸机启动训练，不经过平台



计划测试
------------------------------------------------------------
1. 回归验证： 使用相同的镜像，模型框架、脚本和数据集
2. 对比平台验证和裸机验证
3. 对比不同的存储配置

推荐存储方案
------------------------------------------------------------
1. 独立分布式存储
2. 不同节点不同链路
3. 对比平台层和裸机层